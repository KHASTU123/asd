// app/api/rag/chat/route.ts
import { NextRequest, NextResponse } from "next/server";
import { Pinecone } from "@pinecone-database/pinecone";
import { CohereClient } from "cohere-ai";

// ‚úÖ Kh·ªüi t·∫°o Pinecone client
const pc = new Pinecone({
  apiKey: process.env.PINECONE_API_KEY!,
});

const index = pc.index(process.env.PINECONE_INDEX!);

// ‚úÖ Kh·ªüi t·∫°o Cohere client
const cohere = new CohereClient({
  token: process.env.COHERE_API_KEY!,
});

// üîπ T·∫°o embedding b·∫±ng Cohere
async function embedText(text: string): Promise<number[]> {
  const resp: EmbedResponse = await cohere.embed({
    model: "embed-multilingual-v3.0",
    texts: [text],
    input_type: "search_document",
  });

  return resp.embeddings[0];
}

// üîπ Convert conversation t·ª´ OpenAI format ‚Üí Cohere format
function convertConversation(conv: Array<{ role: string; content: string }>) {
  return conv
    .filter(msg => msg.role === "user" || msg.role === "assistant")
    .map(msg => ({
      role: msg.role === "user" ? "USER" : "CHATBOT",
      message: msg.content,
    }));
}
export async function POST(req: NextRequest) {
  try {
    const { message, conversation = [], userId, childId } = await req.json();

    if (!message) {
      return NextResponse.json(
        { success: false, error: "Thi·∫øu message" },
        { status: 400 }
      );
    }

    // 1) Embed c√¢u h·ªèi
    const qEmb = await embedText(message);

    // 2) Debug: check index info tr∆∞·ªõc khi query
    try {
      const stats = await index.describeIndexStats();
      console.log("‚úÖ Pinecone index stats:", stats);
    } catch (err) {
      console.error("‚ùå Kh√¥ng th·ªÉ l·∫•y index stats t·ª´ Pinecone:", err);
    }

    // 3) T·∫°o filter (ch·ªâ th√™m khi c√≥ gi√° tr·ªã th·∫≠t)
    const filter: Record<string, string> = {};
    if (userId) filter.userId = userId;
    if (childId) filter.childId = childId;

    // 4) Query Pinecone
    const results = await index.query({
      topK: 5,
      vector: qEmb,
      includeMetadata: true,
      ...(Object.keys(filter).length > 0 ? { filter } : {}),
    });

    const hits = (results.matches ?? []).map(m => m.metadata);
    const context = hits
      .map(
        (h: any, i: number) =>
          `Source ${i + 1} (${h.docId || "no-id"}):\n${h.text}`
      )
      .join("\n\n---\n\n");

    // 5) Prompt
    const system = `B·∫°n l√† tr·ª£ l√Ω AI c·ªßa ph·ª• huynh, tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu h·ªì s∆°, nh·∫≠t k√Ω, y t·∫ø trong CONTEXT.
N·∫øu kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu, h√£y n√≥i r√µ "kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu".`;

    const userPrompt = `${system}\n\nUser: ${message}\n\nCONTEXT:\n${context}`;

    // 6) Convert conversation sang format c·ªßa Cohere
    const chatHistory = convertConversation(conversation);

    // 7) G·ªçi Cohere chat
    const chatResp = await cohere.chat({
      model: "command-r-plus", // ho·∫∑c "command-r"
      message: userPrompt,
      temperature: 0.2,
      chat_history: chatHistory,
    });

    const answer = chatResp.text || "Xin l·ªói, ch∆∞a c√≥ c√¢u tr·∫£ l·ªùi.";

    return NextResponse.json({
      success: true,
      answer,
      sources: hits.slice(0, 5),
    });
  } catch (err: any) {
    console.error("‚ùå Chat error:", err);
    return NextResponse.json(
      { success: false, error: err.message },
      { status: 500 }
    );
  }
}

